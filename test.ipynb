{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import sys\n",
    "sys.path.insert(0, 'src/')\n",
    "\n",
    "from src.model.vae import VAE_Encoder, VAE_Decoder\n",
    "from src.model.config import StableDiffusionConfig\n",
    "from src.model.unet import UNet\n",
    "from src.model.clip import CLIPEncoder\n",
    "\n",
    "from src.model.diffusion import StableDiffusion\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "config = StableDiffusionConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stable Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.randn((1, config.img_channels, config.img_size, config.img_size))\n",
    "tokens = torch.randint(low=0, high=config.vocab_size, size=(1, config.clip_seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StableDiffusion(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (1, config.img_channels, config.img_size, config.img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 6.4163e-02,  1.3262e-01,  3.0984e-01,  ..., -1.7970e-01,\n",
       "            1.2657e-01,  1.2361e-01],\n",
       "          [-1.4720e-01,  7.8002e-02,  1.1408e-01,  ...,  7.2566e-02,\n",
       "            1.7217e-01, -1.3937e-02],\n",
       "          [ 1.9099e-01,  9.7678e-02,  3.7384e-01,  ..., -8.2584e-02,\n",
       "           -7.7080e-02, -3.1102e-02],\n",
       "          ...,\n",
       "          [ 2.9921e-01, -1.2221e-01,  6.0580e-02,  ..., -1.0437e-01,\n",
       "            3.0239e-01, -6.4472e-02],\n",
       "          [-1.8619e-01,  1.2759e-01,  1.3594e-01,  ...,  1.2249e-01,\n",
       "            1.3668e-02,  5.8419e-02],\n",
       "          [-1.1794e-01, -2.5002e-01,  1.4206e-02,  ...,  1.8329e-02,\n",
       "           -1.3065e-02,  2.1070e-01]],\n",
       "\n",
       "         [[-2.3845e-02,  1.8576e-01, -1.5871e-01,  ...,  1.7736e-01,\n",
       "           -1.0556e-01,  9.8693e-03],\n",
       "          [ 7.9908e-02, -1.6531e-01,  8.5423e-02,  ...,  1.4956e-01,\n",
       "            1.0378e-01,  2.6972e-01],\n",
       "          [ 2.6183e-01, -1.1397e-01,  2.9007e-01,  ...,  1.3690e-01,\n",
       "           -2.0569e-01, -5.3160e-02],\n",
       "          ...,\n",
       "          [ 2.6797e-02, -1.9258e-01,  4.4590e-02,  ..., -1.8740e-01,\n",
       "           -3.0912e-01,  2.1756e-02],\n",
       "          [-2.8915e-01,  3.5917e-02, -1.8082e-01,  ..., -1.2887e-01,\n",
       "            2.2416e-01, -1.6696e-01],\n",
       "          [ 9.7476e-02,  6.5859e-02,  6.4152e-03,  ..., -3.1470e-01,\n",
       "           -2.5141e-01,  3.9945e-01]],\n",
       "\n",
       "         [[ 3.8810e-01,  1.4300e-02, -1.7364e-01,  ..., -9.5545e-02,\n",
       "           -1.4220e-01,  1.9209e-01],\n",
       "          [-5.7420e-02,  1.2530e-01,  8.7655e-02,  ...,  1.3198e-01,\n",
       "            4.2196e-01,  2.2247e-01],\n",
       "          [ 7.0634e-02, -1.0389e-01,  4.9818e-02,  ..., -4.3241e-02,\n",
       "            1.1878e-02, -1.5654e-01],\n",
       "          ...,\n",
       "          [-3.2964e-02, -1.5466e-01,  1.5892e-01,  ..., -1.1700e-01,\n",
       "            1.8212e-01,  1.1219e-02],\n",
       "          [ 2.9289e-01,  3.2447e-02, -4.5058e-02,  ...,  1.7045e-01,\n",
       "            5.3427e-02, -7.9294e-03],\n",
       "          [ 2.0236e-01, -2.6655e-01,  6.4061e-02,  ...,  2.6318e-01,\n",
       "            1.0986e-01,  1.3730e-01]],\n",
       "\n",
       "         [[ 5.7781e-02, -2.8529e-02,  9.3574e-02,  ...,  2.2322e-01,\n",
       "           -1.0215e-01, -1.9148e-02],\n",
       "          [-3.9598e-02, -1.9994e-01, -7.0304e-02,  ..., -1.0138e-01,\n",
       "           -1.6303e-01,  2.5994e-02],\n",
       "          [-3.5186e-01,  1.4141e-01, -4.3551e-01,  ...,  5.3302e-02,\n",
       "           -4.5042e-02, -2.1087e-01],\n",
       "          ...,\n",
       "          [ 2.3846e-01, -2.1839e-01,  7.6601e-02,  ...,  4.0142e-02,\n",
       "            5.2147e-02, -4.6859e-01],\n",
       "          [ 7.5202e-02,  2.4758e-01,  1.0537e-01,  ..., -1.9092e-01,\n",
       "            4.1256e-01,  1.6146e-01],\n",
       "          [-2.8416e-02, -2.9066e-02, -1.9971e-01,  ..., -1.8583e-03,\n",
       "           -1.4223e-01,  6.0902e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 7.2654e-02, -7.3604e-02,  9.3662e-02,  ...,  2.7657e-02,\n",
       "            1.7274e-01,  1.0571e-02],\n",
       "          [ 1.1512e-01, -3.3000e-02,  8.0425e-03,  ..., -4.7227e-02,\n",
       "           -2.1641e-01,  2.2458e-01],\n",
       "          [-2.8108e-01,  9.5550e-02,  8.0215e-02,  ..., -1.1301e-01,\n",
       "           -5.3160e-02,  1.1200e-01],\n",
       "          ...,\n",
       "          [-4.8091e-02,  3.3661e-03, -9.9938e-02,  ..., -6.7794e-02,\n",
       "           -8.8073e-02, -7.0602e-02],\n",
       "          [ 2.3229e-01,  5.2759e-02, -1.6213e-01,  ...,  1.0257e-01,\n",
       "           -9.0729e-04,  2.9876e-01],\n",
       "          [-3.0668e-02, -3.5881e-01, -1.4162e-01,  ...,  8.5353e-02,\n",
       "           -7.6401e-03, -1.7934e-01]],\n",
       "\n",
       "         [[-1.5488e-01,  2.9476e-02, -3.3202e-01,  ..., -8.1390e-02,\n",
       "           -1.7210e-01,  1.7227e-01],\n",
       "          [-1.9304e-01, -2.7108e-01,  2.2049e-01,  ...,  2.5624e-01,\n",
       "            3.0237e-01, -8.9141e-02],\n",
       "          [-2.7740e-01, -2.1539e-02, -7.8428e-02,  ..., -3.6614e-01,\n",
       "            6.6406e-02,  2.0087e-01],\n",
       "          ...,\n",
       "          [ 2.7649e-01,  8.9121e-03, -5.7262e-03,  ...,  2.1434e-01,\n",
       "           -2.6959e-01, -6.3557e-02],\n",
       "          [-7.7241e-02,  2.6417e-01, -1.7158e-01,  ..., -1.6213e-01,\n",
       "            1.5308e-01, -2.9328e-01],\n",
       "          [-4.2043e-02, -3.4572e-01, -1.9371e-01,  ..., -3.1639e-01,\n",
       "           -1.2268e-01, -3.4797e-01]],\n",
       "\n",
       "         [[-2.5008e-02, -8.5708e-02,  7.0029e-03,  ..., -6.5171e-02,\n",
       "            6.3490e-02, -3.8824e-02],\n",
       "          [-1.0206e-01, -5.0393e-02, -5.0218e-02,  ...,  3.2075e-02,\n",
       "            1.2215e-01, -1.3280e-01],\n",
       "          [ 1.9401e-01,  3.1860e-01,  4.8152e-02,  ...,  1.4425e-02,\n",
       "            9.3552e-02,  1.3072e-01],\n",
       "          ...,\n",
       "          [-1.8488e-02, -1.5196e-01,  1.7982e-01,  ..., -1.0057e-01,\n",
       "           -6.8568e-03,  1.1170e-01],\n",
       "          [ 1.2699e-01, -2.3797e-01, -1.5594e-01,  ...,  1.3930e-01,\n",
       "            4.7795e-02,  1.6705e-01],\n",
       "          [ 1.2538e-01,  2.3738e-01,  1.6601e-01,  ...,  4.6428e-02,\n",
       "           -1.2351e-01, -4.7183e-02]],\n",
       "\n",
       "         [[-2.4023e-01,  4.9717e-02,  4.3834e-02,  ..., -8.7159e-02,\n",
       "           -1.1495e-01,  1.1926e-01],\n",
       "          [-2.9047e-02, -1.1212e-01, -2.2282e-01,  ...,  7.4161e-02,\n",
       "            1.9522e-01, -3.1838e-01],\n",
       "          [ 3.0596e-01, -9.9018e-02, -1.6703e-02,  ..., -1.6429e-01,\n",
       "           -2.9926e-02, -3.6363e-01],\n",
       "          ...,\n",
       "          [ 1.8467e-01, -2.6765e-01, -1.1105e-01,  ..., -1.6504e-03,\n",
       "           -1.5045e-02, -3.8602e-02],\n",
       "          [-3.4792e-02,  2.8549e-01, -1.3458e-01,  ...,  2.8621e-03,\n",
       "            2.1519e-01, -1.5841e-01],\n",
       "          [ 5.7258e-02,  3.1539e-01,  1.9901e-01,  ...,  2.4106e-02,\n",
       "            4.1629e-02,  1.1171e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.7081e-02,  5.8763e-03, -2.8778e-01,  ...,  3.4347e-03,\n",
       "            4.1838e-02,  1.3807e-01],\n",
       "          [ 5.4170e-02, -6.7972e-04,  1.5955e-02,  ...,  1.3720e-01,\n",
       "            1.6979e-01, -1.6604e-01],\n",
       "          [-3.8923e-01, -1.5348e-02,  2.1075e-01,  ..., -2.7979e-01,\n",
       "           -8.5607e-02,  2.5434e-02],\n",
       "          ...,\n",
       "          [ 2.7105e-02,  2.5221e-01, -1.3178e-02,  ..., -1.3601e-02,\n",
       "           -1.9352e-01, -8.2184e-02],\n",
       "          [-1.4448e-01, -3.4673e-02,  1.4359e-01,  ...,  3.2668e-02,\n",
       "           -1.6028e-01,  9.2318e-02],\n",
       "          [-1.3629e-01,  1.4218e-01, -1.4611e-01,  ...,  4.4471e-02,\n",
       "            1.6454e-01,  1.9526e-01]],\n",
       "\n",
       "         [[-8.0617e-02, -3.8161e-01,  1.3915e-01,  ..., -2.2961e-01,\n",
       "            4.0487e-03,  7.1971e-03],\n",
       "          [ 1.9293e-01, -8.9423e-02, -3.9837e-02,  ..., -7.7249e-02,\n",
       "           -3.7497e-02,  2.2487e-01],\n",
       "          [-3.2265e-02,  3.9800e-01, -5.7234e-02,  ..., -1.6993e-01,\n",
       "           -3.2051e-02, -1.1213e-01],\n",
       "          ...,\n",
       "          [ 1.7087e-01, -1.7933e-01, -3.0102e-01,  ..., -3.4390e-01,\n",
       "           -2.6745e-01, -1.9483e-02],\n",
       "          [ 1.5965e-01, -2.9528e-02, -3.5575e-01,  ...,  2.1095e-01,\n",
       "            3.1614e-02,  2.1921e-01],\n",
       "          [-9.5591e-02,  1.4068e-01,  3.7145e-02,  ..., -2.8107e-02,\n",
       "            1.0831e-01, -1.2783e-01]],\n",
       "\n",
       "         [[ 2.3437e-01, -3.4410e-01,  7.5919e-02,  ..., -3.0959e-01,\n",
       "            2.6072e-01,  4.3784e-01],\n",
       "          [ 1.3394e-01,  9.6367e-02, -1.5744e-01,  ..., -3.7733e-02,\n",
       "            1.0853e-02,  3.7780e-02],\n",
       "          [ 3.8587e-03,  5.0381e-02,  3.3910e-02,  ..., -7.7322e-02,\n",
       "           -1.8494e-01, -2.4955e-02],\n",
       "          ...,\n",
       "          [ 5.7789e-03,  3.0823e-02,  1.0969e-01,  ...,  1.7594e-01,\n",
       "           -1.1115e-01, -5.3400e-02],\n",
       "          [ 2.9461e-02, -4.5673e-02,  6.6864e-02,  ..., -8.6662e-02,\n",
       "            5.1717e-02,  3.1217e-01],\n",
       "          [ 8.8144e-02, -2.2582e-01,  2.0267e-02,  ..., -8.7884e-03,\n",
       "           -2.8599e-02,  1.0184e-01]],\n",
       "\n",
       "         [[-5.7349e-02,  1.4421e-02,  7.7081e-02,  ..., -2.0797e-01,\n",
       "            2.7740e-01,  6.6236e-02],\n",
       "          [-1.9272e-01,  3.0377e-02, -1.7116e-01,  ...,  8.5216e-02,\n",
       "            2.3769e-01, -6.0334e-03],\n",
       "          [ 1.7313e-01,  7.0614e-02, -3.5781e-02,  ...,  1.7320e-01,\n",
       "            9.5967e-02, -8.2239e-02],\n",
       "          ...,\n",
       "          [-5.0921e-03, -1.8807e-01,  1.3193e-01,  ...,  2.3987e-01,\n",
       "            1.0793e-01, -2.8126e-01],\n",
       "          [ 2.3596e-02,  1.7335e-01,  7.3235e-03,  ...,  1.6222e-01,\n",
       "           -1.3053e-01,  9.0676e-02],\n",
       "          [-2.9015e-02,  1.2646e-01,  8.1956e-02,  ...,  2.8865e-02,\n",
       "           -1.7809e-02, -1.6110e-01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-1.2691e-01,  1.4801e-01,  7.0972e-02,  ..., -1.9140e-02,\n",
       "           -6.2605e-02, -5.2411e-02],\n",
       "          [ 1.0116e-01, -2.0070e-01, -1.4176e-02,  ...,  2.2432e-01,\n",
       "            2.2716e-01,  6.8707e-02],\n",
       "          [ 1.2929e-01,  2.1920e-02, -2.9358e-01,  ..., -1.3614e-01,\n",
       "           -1.3045e-01,  1.8224e-01],\n",
       "          ...,\n",
       "          [-1.1662e-01, -6.0826e-02,  2.6751e-01,  ...,  2.3177e-02,\n",
       "           -7.0266e-02,  1.4254e-01],\n",
       "          [-4.7155e-02, -1.1815e-03,  4.9084e-02,  ..., -1.0031e-01,\n",
       "            4.3969e-02,  9.6830e-02],\n",
       "          [ 2.0238e-01, -2.8170e-01,  1.3981e-02,  ...,  3.4383e-01,\n",
       "           -1.1537e-01, -1.3137e-01]],\n",
       "\n",
       "         [[-1.1526e-03, -2.7933e-01, -2.2299e-01,  ...,  2.0985e-01,\n",
       "            3.5532e-01, -1.1246e-01],\n",
       "          [ 1.3165e-01,  6.0208e-02, -8.2274e-02,  ...,  9.7653e-02,\n",
       "           -7.0446e-02, -1.0282e-01],\n",
       "          [-3.6666e-01, -2.9729e-01, -1.4235e-02,  ...,  3.0245e-01,\n",
       "           -6.1780e-02,  7.7535e-02],\n",
       "          ...,\n",
       "          [-1.6741e-01, -8.7567e-02, -9.2088e-02,  ..., -5.2609e-01,\n",
       "           -2.1371e-01, -3.3386e-01],\n",
       "          [-1.5543e-01, -5.2902e-02,  2.7103e-01,  ...,  1.4692e-01,\n",
       "           -2.3116e-01,  2.1638e-01],\n",
       "          [ 1.5098e-01, -2.8608e-01, -7.1844e-03,  ...,  1.3338e-01,\n",
       "            3.6795e-02, -3.7794e-01]],\n",
       "\n",
       "         [[-4.4578e-02,  1.8293e-01, -1.6113e-02,  ...,  1.6140e-01,\n",
       "            2.7172e-01, -3.6745e-01],\n",
       "          [-5.5529e-02,  2.1431e-02,  6.6025e-02,  ..., -1.3476e-01,\n",
       "            1.0245e-01, -9.6038e-03],\n",
       "          [ 1.6816e-01,  1.2578e-01, -3.1495e-01,  ..., -4.2821e-01,\n",
       "            7.3895e-03,  1.1451e-01],\n",
       "          ...,\n",
       "          [ 4.8007e-02,  2.0020e-02,  1.4595e-01,  ..., -1.2850e-01,\n",
       "           -6.4660e-02,  6.8136e-02],\n",
       "          [-5.3529e-02, -4.5840e-02,  1.1188e-01,  ...,  6.8546e-02,\n",
       "           -5.9898e-02,  9.6148e-02],\n",
       "          [-3.8396e-02,  1.5471e-01,  8.5711e-02,  ...,  2.6904e-01,\n",
       "            1.1358e-01, -1.5899e-03]],\n",
       "\n",
       "         [[-1.6205e-02,  1.0167e-01, -7.4264e-02,  ...,  1.4297e-02,\n",
       "            1.9671e-01, -3.5051e-02],\n",
       "          [-7.9922e-03, -1.0029e-01,  3.7728e-01,  ..., -2.0021e-01,\n",
       "           -2.7891e-01,  2.1897e-01],\n",
       "          [-5.9803e-03,  2.3310e-01,  4.1352e-02,  ...,  1.3913e-01,\n",
       "           -1.0342e-02, -7.1429e-03],\n",
       "          ...,\n",
       "          [-1.6724e-01, -2.1083e-02,  1.3634e-01,  ...,  9.6011e-02,\n",
       "            1.2644e-01,  3.8195e-01],\n",
       "          [-5.5915e-02,  9.1209e-02,  1.3786e-02,  ...,  6.4972e-02,\n",
       "            9.2960e-02, -2.9222e-01],\n",
       "          [ 5.1112e-02,  2.2413e-01,  6.4216e-02,  ..., -1.2783e-01,\n",
       "            1.4507e-01, -2.4510e-01]]],\n",
       "\n",
       "\n",
       "        [[[-9.0306e-02, -3.7778e-02, -5.6277e-02,  ..., -1.9428e-02,\n",
       "           -1.0216e-01, -7.5994e-03],\n",
       "          [ 7.4335e-02,  2.6143e-01,  4.8973e-02,  ...,  1.0949e-01,\n",
       "           -3.1613e-01,  1.3639e-01],\n",
       "          [-2.2345e-01, -5.2703e-02,  4.2937e-01,  ...,  1.8797e-01,\n",
       "            1.0750e-01,  1.2792e-01],\n",
       "          ...,\n",
       "          [ 2.7513e-01,  1.1255e-02, -2.4080e-01,  ...,  1.6597e-01,\n",
       "           -4.3418e-02,  2.5716e-01],\n",
       "          [ 2.3329e-01,  3.5803e-01, -5.2642e-02,  ..., -1.3576e-01,\n",
       "            6.2742e-02,  1.4004e-01],\n",
       "          [-2.4557e-01, -1.4445e-01,  1.5123e-01,  ...,  1.6541e-01,\n",
       "           -2.3058e-01, -1.5083e-01]],\n",
       "\n",
       "         [[-4.7532e-02, -1.4911e-01, -4.4018e-01,  ..., -1.0377e-01,\n",
       "           -1.2116e-01, -1.2451e-01],\n",
       "          [-2.0848e-02,  2.2123e-02,  8.9713e-03,  ..., -5.8579e-02,\n",
       "           -7.8469e-02,  2.5879e-01],\n",
       "          [-2.9980e-01, -9.9008e-02, -1.1056e-01,  ..., -4.1106e-01,\n",
       "           -3.3054e-01, -2.9498e-01],\n",
       "          ...,\n",
       "          [ 5.8795e-01,  6.5894e-02,  5.7719e-02,  ..., -8.3739e-02,\n",
       "            1.9951e-01, -4.7617e-02],\n",
       "          [-4.7093e-02,  1.5300e-01,  1.0199e-02,  ...,  1.0499e-01,\n",
       "            2.5952e-01, -9.8961e-02],\n",
       "          [-3.4123e-01,  1.9883e-01, -3.7591e-01,  ..., -3.7782e-01,\n",
       "           -7.4362e-02,  2.2422e-01]],\n",
       "\n",
       "         [[ 8.2663e-02,  2.5175e-02, -2.0512e-01,  ..., -2.4053e-01,\n",
       "           -6.2920e-02,  2.1302e-01],\n",
       "          [ 1.4778e-01,  4.9618e-02, -3.7028e-02,  ...,  1.2296e-03,\n",
       "            2.2853e-01,  1.1160e-01],\n",
       "          [ 1.2283e-01, -4.2772e-02,  5.9700e-02,  ...,  1.5662e-02,\n",
       "            1.6333e-02, -2.0782e-01],\n",
       "          ...,\n",
       "          [-1.1030e-01, -7.0192e-02,  7.2628e-02,  ..., -2.7909e-01,\n",
       "           -4.4998e-02,  1.1927e-01],\n",
       "          [-4.8756e-02, -1.4741e-01,  1.0441e-01,  ...,  6.3431e-02,\n",
       "            6.1293e-02, -1.2715e-01],\n",
       "          [-1.1594e-01,  4.9057e-02,  1.9249e-01,  ...,  1.4219e-01,\n",
       "            1.6876e-01, -4.3222e-02]],\n",
       "\n",
       "         [[-8.2993e-02, -2.6591e-01, -1.1044e-01,  ..., -6.1952e-02,\n",
       "           -4.5958e-04,  1.0294e-02],\n",
       "          [-4.4563e-01,  2.4998e-01, -1.8180e-01,  ...,  9.5992e-03,\n",
       "           -2.4272e-02, -1.4888e-01],\n",
       "          [ 2.4862e-03, -6.2986e-03,  3.6642e-01,  ..., -2.5876e-01,\n",
       "            3.4810e-02,  6.2315e-02],\n",
       "          ...,\n",
       "          [ 6.9520e-02, -1.3452e-01, -1.7961e-01,  ..., -4.6832e-02,\n",
       "            5.1122e-02,  1.7277e-01],\n",
       "          [-1.3344e-01,  1.0463e-01,  6.2695e-02,  ...,  1.2720e-01,\n",
       "           -1.2306e-01, -6.6037e-02],\n",
       "          [-4.5305e-02,  1.5081e-01, -5.3182e-02,  ...,  1.6596e-01,\n",
       "            3.2057e-02, -2.0522e-02]]],\n",
       "\n",
       "\n",
       "        [[[-2.1207e-02,  1.8498e-02, -2.7163e-02,  ..., -1.5115e-01,\n",
       "            7.9416e-02, -1.3635e-01],\n",
       "          [ 2.0280e-01,  1.7733e-01, -6.8691e-02,  ..., -1.8179e-01,\n",
       "            1.8738e-02, -2.9698e-02],\n",
       "          [ 6.8214e-01,  4.2910e-02,  3.5228e-02,  ...,  7.3061e-02,\n",
       "            3.1228e-02, -1.9931e-01],\n",
       "          ...,\n",
       "          [ 2.0988e-02,  5.9365e-02, -1.1153e-01,  ..., -1.0794e-01,\n",
       "           -2.2114e-01, -1.3576e-01],\n",
       "          [-2.4196e-01,  3.6437e-02, -2.1074e-02,  ..., -3.4898e-02,\n",
       "           -8.2604e-02,  6.3321e-02],\n",
       "          [ 1.2666e-02, -2.7554e-01,  6.5594e-02,  ..., -2.0950e-01,\n",
       "           -1.3707e-01,  2.4407e-01]],\n",
       "\n",
       "         [[-1.4623e-01, -3.1135e-01, -3.5946e-01,  ...,  1.6839e-01,\n",
       "            4.0221e-02,  1.5921e-01],\n",
       "          [-8.4493e-02,  1.8119e-01,  2.5781e-01,  ...,  1.8292e-01,\n",
       "            1.6860e-01,  2.6516e-01],\n",
       "          [-2.7927e-01,  6.8732e-02, -2.6635e-01,  ..., -2.7655e-01,\n",
       "           -3.1380e-01, -2.2009e-01],\n",
       "          ...,\n",
       "          [-2.2327e-01,  5.2924e-02, -5.0730e-01,  ...,  2.5116e-01,\n",
       "           -2.0819e-01, -9.8918e-02],\n",
       "          [-6.5940e-02, -2.1973e-01,  2.0456e-02,  ..., -6.7060e-02,\n",
       "           -3.2775e-01,  1.7274e-01],\n",
       "          [-2.1201e-01, -3.7252e-01, -6.1059e-01,  ..., -1.8366e-01,\n",
       "           -1.0598e-01, -5.2544e-02]],\n",
       "\n",
       "         [[ 1.2987e-01, -1.5732e-01, -6.3038e-02,  ...,  9.3443e-02,\n",
       "            1.9607e-01,  8.5579e-02],\n",
       "          [ 5.2109e-02,  3.0181e-02,  9.4810e-02,  ...,  2.0211e-01,\n",
       "           -6.3498e-02, -1.3751e-01],\n",
       "          [ 2.7296e-01, -1.3821e-01,  9.6691e-02,  ..., -3.2328e-01,\n",
       "            1.7437e-01,  3.8958e-02],\n",
       "          ...,\n",
       "          [ 2.8241e-02, -2.4486e-01,  1.2872e-01,  ...,  2.7923e-01,\n",
       "           -8.5369e-02,  2.1263e-01],\n",
       "          [-4.9192e-02, -1.1755e-01, -3.4456e-01,  ..., -1.4866e-01,\n",
       "           -4.3266e-02, -6.9596e-02],\n",
       "          [-2.8802e-01, -1.2642e-02,  1.9286e-01,  ..., -6.3404e-02,\n",
       "           -1.3965e-01,  9.0519e-02]],\n",
       "\n",
       "         [[-1.0496e-01,  4.0053e-01,  8.9119e-02,  ...,  1.3076e-01,\n",
       "            9.1838e-02, -8.4036e-03],\n",
       "          [ 4.7518e-02, -1.8881e-01,  1.7105e-01,  ..., -1.9870e-01,\n",
       "            2.4500e-01, -3.2386e-01],\n",
       "          [-2.6353e-01, -1.5632e-01, -2.9944e-01,  ...,  1.9562e-01,\n",
       "           -1.2302e-01, -2.3386e-01],\n",
       "          ...,\n",
       "          [ 1.3859e-01, -1.2925e-01,  1.3980e-01,  ...,  1.4159e-01,\n",
       "            1.0838e-01, -1.1700e-01],\n",
       "          [-4.6539e-02,  7.7177e-02,  2.4972e-01,  ...,  1.1192e-01,\n",
       "           -4.4414e-02, -8.6580e-02],\n",
       "          [-3.9539e-01,  7.2401e-02,  2.0246e-01,  ..., -3.7537e-01,\n",
       "           -2.8444e-02,  3.0266e-01]]]], device='cuda:0',\n",
       "       grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(img, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "StableDiffusion                                         [32, 4, 32, 32]           1,008,786,327\n",
       "├─VAE_Encoder: 1-1                                      [32, 4, 32, 32]           --\n",
       "│    └─Conv2d: 2-1                                      [1, 128, 256, 256]        3,456\n",
       "│    └─ModuleList: 2-2                                  --                        --\n",
       "│    │    └─VAE_Block: 3-1                              [1, 128, 128, 128]        442,880\n",
       "│    │    └─VAE_Block: 3-2                              [1, 256, 64, 64]          1,508,352\n",
       "│    │    └─VAE_Block: 3-3                              [1, 512, 32, 32]          6,031,360\n",
       "│    └─Sequential: 2-3                                  [1, 512, 32, 32]          --\n",
       "│    │    └─VAE_Block: 3-4                              [1, 512, 32, 32]          4,720,640\n",
       "│    │    └─VAE_Block: 3-5                              [1, 512, 32, 32]          4,720,640\n",
       "│    │    └─VAE_AttentionBlock: 3-6                     [1, 512, 32, 32]          1,051,648\n",
       "│    │    └─VAE_Block: 3-7                              [1, 512, 32, 32]          4,720,640\n",
       "│    │    └─GroupNorm: 3-8                              [1, 512, 32, 32]          1,024\n",
       "│    │    └─SiLU: 3-9                                   [1, 512, 32, 32]          --\n",
       "│    └─Sequential: 2-4                                  [1, 8, 32, 32]            --\n",
       "│    │    └─Conv2d: 3-10                                [1, 8, 32, 32]            36,872\n",
       "│    │    └─Conv2d: 3-11                                [1, 8, 32, 32]            72\n",
       "=========================================================================================================\n",
       "Total params: 1,032,023,911\n",
       "Trainable params: 1,032,023,911\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 71.41\n",
       "=========================================================================================================\n",
       "Input size (MB): 0.79\n",
       "Forward/backward pass size (MB): 662.83\n",
       "Params size (MB): 92.95\n",
       "Estimated Total Size (MB): 756.56\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, [img_size, (1, config.clip_seq_len)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23237584\n"
     ]
    }
   ],
   "source": [
    "enc = VAE_Encoder(config.img_channels, config.vae_features_dims, config.vae_num_groups, config.vae_num_heads, config.vae_dropout, config.vae_latent_dim)\n",
    "\n",
    "print(sum(p.numel() for p in enc.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(config.vae_latent_dim, config.unet_features_dims, config.unet_attn_num_heads, config.unet_attn_dim, config.unet_time_emb_dim, config.unet_time_emb_dim_scale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "852620804"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 3, 512, 512]), torch.Size([1, 4, 64, 64])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[img.shape, noise.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "VAE_Encoder                                        [1, 4, 64, 64]            --\n",
       "├─Conv2d: 1-1                                      [1, 128, 512, 512]        3,456\n",
       "├─ModuleList: 1-2                                  --                        --\n",
       "│    └─VAE_Block: 2-1                              [1, 128, 256, 256]        --\n",
       "│    │    └─PrenormResidualConnection: 3-1         [1, 128, 512, 512]        147,712\n",
       "│    │    └─PrenormResidualConnection: 3-2         [1, 128, 512, 512]        147,712\n",
       "│    │    └─Conv2d: 3-3                            [1, 128, 256, 256]        147,456\n",
       "│    └─VAE_Block: 2-2                              [1, 256, 128, 128]        --\n",
       "│    │    └─PrenormResidualConnection: 3-4         [1, 256, 256, 256]        328,192\n",
       "│    │    └─PrenormResidualConnection: 3-5         [1, 256, 256, 256]        590,336\n",
       "│    │    └─Conv2d: 3-6                            [1, 256, 128, 128]        589,824\n",
       "│    └─VAE_Block: 2-3                              [1, 512, 64, 64]          --\n",
       "│    │    └─PrenormResidualConnection: 3-7         [1, 512, 128, 128]        1,311,744\n",
       "│    │    └─PrenormResidualConnection: 3-8         [1, 512, 128, 128]        2,360,320\n",
       "│    │    └─Conv2d: 3-9                            [1, 512, 64, 64]          2,359,296\n",
       "├─Sequential: 1-3                                  [1, 512, 64, 64]          --\n",
       "│    └─VAE_Block: 2-4                              [1, 512, 64, 64]          --\n",
       "│    │    └─PrenormResidualConnection: 3-10        [1, 512, 64, 64]          2,360,320\n",
       "│    │    └─PrenormResidualConnection: 3-11        [1, 512, 64, 64]          2,360,320\n",
       "│    └─VAE_Block: 2-5                              [1, 512, 64, 64]          --\n",
       "│    │    └─PrenormResidualConnection: 3-12        [1, 512, 64, 64]          2,360,320\n",
       "│    │    └─PrenormResidualConnection: 3-13        [1, 512, 64, 64]          2,360,320\n",
       "│    └─VAE_AttentionBlock: 2-6                     [1, 512, 64, 64]          1,024\n",
       "│    │    └─MultiheadAttention: 3-14               [1, 4096, 512]            1,050,624\n",
       "│    └─VAE_Block: 2-7                              [1, 512, 64, 64]          --\n",
       "│    │    └─PrenormResidualConnection: 3-15        [1, 512, 64, 64]          2,360,320\n",
       "│    │    └─PrenormResidualConnection: 3-16        [1, 512, 64, 64]          2,360,320\n",
       "│    └─GroupNorm: 2-8                              [1, 512, 64, 64]          1,024\n",
       "│    └─SiLU: 2-9                                   [1, 512, 64, 64]          --\n",
       "├─Sequential: 1-4                                  [1, 8, 64, 64]            --\n",
       "│    └─Conv2d: 2-10                                [1, 8, 64, 64]            36,872\n",
       "│    └─Conv2d: 2-11                                [1, 8, 64, 64]            72\n",
       "====================================================================================================\n",
       "Total params: 23,237,584\n",
       "Trainable params: 23,237,584\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 285.62\n",
       "====================================================================================================\n",
       "Input size (MB): 3.21\n",
       "Forward/backward pass size (MB): 2584.22\n",
       "Params size (MB): 88.74\n",
       "Estimated Total Size (MB): 2676.17\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(enc, [(1, 3, 512, 512), (1, 4, 64, 64)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SwitchSequential.forward() missing 1 required positional argument: 'time'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m time \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m1\u001b[39m, config\u001b[38;5;241m.\u001b[39munet_time_emb_dim))\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\foret\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\foret\\OneDrive\\Рабочий стол\\Projects\\Stable_diffusion\\src\\model\\unet.py:321\u001b[0m, in \u001b[0;36mUNet.forward\u001b[1;34m(self, x, time)\u001b[0m\n\u001b[0;32m    318\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_embedding(time)\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder:\n\u001b[1;32m--> 321\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\foret\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[1;31mTypeError\u001b[0m: SwitchSequential.forward() missing 1 required positional argument: 'time'"
     ]
    }
   ],
   "source": [
    "time = torch.randn((1, config.unet_time_emb_dim))\n",
    "model(out, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 77])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = CLIPEncoder(config.vocab_size, config.clip_emb_dim, config.clip_seq_len,\n",
    "                   config.clip_attn_num_heads, config.clip_emb_dim_scale_factor, \n",
    "                   config.clip_num_layers, config.clip_dropout).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123060480"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in clip.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNet_AttentionBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_emb = clip(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 77, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 64, 64])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = VAE_Decoder(config.vae_latent_dim, config.vae_features_dims, config.vae_num_groups, config.vae_dropout, config.vae_num_heads, config.img_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32367379\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in dec.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = dec.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 64, 64])\n",
      "torch.Size([1, 512, 64, 64])\n",
      "torch.Size([1, 512, 64, 64])\n",
      "torch.Size([1, 512, 128, 128])\n",
      "torch.Size([1, 256, 256, 256])\n",
      "torch.Size([1, 128, 512, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 512, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec(out).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

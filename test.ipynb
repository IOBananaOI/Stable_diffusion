{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import sys\n",
    "sys.path.insert(0, 'src/')\n",
    "\n",
    "from src.model.vae import VAE_Encoder, VAE_Decoder\n",
    "from src.model.config import StableDiffusionConfig\n",
    "from src.model.unet import UNet\n",
    "from src.model.clip import CLIPEncoder\n",
    "\n",
    "from src.model.diffusion import StableDiffusion\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "config = StableDiffusionConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stable Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.randn((1, config.img_channels, config.img_size, config.img_size))\n",
    "tokens = torch.randint(low=0, high=config.vocab_size, size=(1, config.clip_seq_len))\n",
    "time = torch.randn((1, config.unet_time_emb_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StableDiffusion(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (1, config.img_channels, config.img_size, config.img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "UNet.forward() missing 3 required positional arguments: 'x', 'time', and 'context'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\foret\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\foret\\OneDrive\\Рабочий стол\\Projects\\Stable_diffusion\\src\\model\\diffusion.py:63\u001b[0m, in \u001b[0;36mStableDiffusion.forward\u001b[1;34m(self, img, caption, time)\u001b[0m\n\u001b[0;32m     59\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip(caption)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# UNET\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# # VAE Decoder\u001b[39;00m\n\u001b[0;32m     66\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvae_dec(z)\n",
      "File \u001b[1;32mc:\\Users\\foret\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[1;31mTypeError\u001b[0m: UNet.forward() missing 3 required positional arguments: 'x', 'time', and 'context'"
     ]
    }
   ],
   "source": [
    "model(img, tokens, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "StableDiffusion                                         [32, 4, 32, 32]           882,807,447\n",
       "├─VAE_Encoder: 1-1                                      [32, 4, 32, 32]           --\n",
       "│    └─Conv2d: 2-1                                      [1, 128, 256, 256]        3,456\n",
       "│    └─ModuleList: 2-2                                  --                        --\n",
       "│    │    └─VAE_Block: 3-1                              [1, 128, 128, 128]        442,880\n",
       "│    │    └─VAE_Block: 3-2                              [1, 256, 64, 64]          1,508,352\n",
       "│    │    └─VAE_Block: 3-3                              [1, 512, 32, 32]          6,031,360\n",
       "│    └─Sequential: 2-3                                  [1, 512, 32, 32]          --\n",
       "│    │    └─VAE_Block: 3-4                              [1, 512, 32, 32]          4,720,640\n",
       "│    │    └─VAE_Block: 3-5                              [1, 512, 32, 32]          4,720,640\n",
       "│    │    └─VAE_AttentionBlock: 3-6                     [1, 512, 32, 32]          1,051,648\n",
       "│    │    └─VAE_Block: 3-7                              [1, 512, 32, 32]          4,720,640\n",
       "│    │    └─GroupNorm: 3-8                              [1, 512, 32, 32]          1,024\n",
       "│    │    └─SiLU: 3-9                                   [1, 512, 32, 32]          --\n",
       "│    └─Sequential: 2-4                                  [1, 8, 32, 32]            --\n",
       "│    │    └─Conv2d: 3-10                                [1, 8, 32, 32]            36,872\n",
       "│    │    └─Conv2d: 3-11                                [1, 8, 32, 32]            72\n",
       "├─CLIPEncoder: 1-2                                      [1, 77, 768]              --\n",
       "│    └─CLIPEmbedding: 2-5                               [1, 77, 768]              59,136\n",
       "│    │    └─Embedding: 3-12                             [1, 77, 768]              37,945,344\n",
       "│    └─ModuleList: 2-6                                  --                        --\n",
       "│    │    └─CLIPLayer: 3-13                             [1, 77, 768]              7,087,872\n",
       "│    │    └─CLIPLayer: 3-14                             [1, 77, 768]              7,087,872\n",
       "│    │    └─CLIPLayer: 3-15                             [1, 77, 768]              7,087,872\n",
       "│    │    └─CLIPLayer: 3-16                             [1, 77, 768]              7,087,872\n",
       "│    │    └─CLIPLayer: 3-17                             [1, 77, 768]              7,087,872\n",
       "│    │    └─CLIPLayer: 3-18                             [1, 77, 768]              7,087,872\n",
       "│    │    └─CLIPLayer: 3-19                             [1, 77, 768]              7,087,872\n",
       "│    │    └─CLIPLayer: 3-20                             [1, 77, 768]              7,087,872\n",
       "│    │    └─CLIPLayer: 3-21                             [1, 77, 768]              7,087,872\n",
       "│    │    └─CLIPLayer: 3-22                             [1, 77, 768]              7,087,872\n",
       "│    │    └─CLIPLayer: 3-23                             [1, 77, 768]              7,087,872\n",
       "│    │    └─CLIPLayer: 3-24                             [1, 77, 768]              7,087,872\n",
       "│    └─LayerNorm: 2-7                                   [1, 77, 768]              1,536\n",
       "=========================================================================================================\n",
       "Total params: 1,029,105,511\n",
       "Trainable params: 1,029,105,511\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 71.53\n",
       "=========================================================================================================\n",
       "Input size (MB): 0.79\n",
       "Forward/backward pass size (MB): 726.22\n",
       "Params size (MB): 584.95\n",
       "Estimated Total Size (MB): 1311.96\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, [img_size, (1, config.clip_seq_len)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23237584\n"
     ]
    }
   ],
   "source": [
    "enc = VAE_Encoder(config.img_channels, config.vae_features_dims, config.vae_num_groups, config.vae_num_heads, config.vae_dropout, config.vae_latent_dim)\n",
    "\n",
    "print(sum(p.numel() for p in enc.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(config.vae_latent_dim, config.unet_features_dims, config.unet_attn_num_heads, config.unet_attn_dim, config.unet_time_emb_dim, config.unet_time_emb_dim_scale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "852620804"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 3, 512, 512]), torch.Size([1, 4, 64, 64])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[img.shape, noise.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "VAE_Encoder                                        [1, 4, 64, 64]            --\n",
       "├─Conv2d: 1-1                                      [1, 128, 512, 512]        3,456\n",
       "├─ModuleList: 1-2                                  --                        --\n",
       "│    └─VAE_Block: 2-1                              [1, 128, 256, 256]        --\n",
       "│    │    └─PrenormResidualConnection: 3-1         [1, 128, 512, 512]        147,712\n",
       "│    │    └─PrenormResidualConnection: 3-2         [1, 128, 512, 512]        147,712\n",
       "│    │    └─Conv2d: 3-3                            [1, 128, 256, 256]        147,456\n",
       "│    └─VAE_Block: 2-2                              [1, 256, 128, 128]        --\n",
       "│    │    └─PrenormResidualConnection: 3-4         [1, 256, 256, 256]        328,192\n",
       "│    │    └─PrenormResidualConnection: 3-5         [1, 256, 256, 256]        590,336\n",
       "│    │    └─Conv2d: 3-6                            [1, 256, 128, 128]        589,824\n",
       "│    └─VAE_Block: 2-3                              [1, 512, 64, 64]          --\n",
       "│    │    └─PrenormResidualConnection: 3-7         [1, 512, 128, 128]        1,311,744\n",
       "│    │    └─PrenormResidualConnection: 3-8         [1, 512, 128, 128]        2,360,320\n",
       "│    │    └─Conv2d: 3-9                            [1, 512, 64, 64]          2,359,296\n",
       "├─Sequential: 1-3                                  [1, 512, 64, 64]          --\n",
       "│    └─VAE_Block: 2-4                              [1, 512, 64, 64]          --\n",
       "│    │    └─PrenormResidualConnection: 3-10        [1, 512, 64, 64]          2,360,320\n",
       "│    │    └─PrenormResidualConnection: 3-11        [1, 512, 64, 64]          2,360,320\n",
       "│    └─VAE_Block: 2-5                              [1, 512, 64, 64]          --\n",
       "│    │    └─PrenormResidualConnection: 3-12        [1, 512, 64, 64]          2,360,320\n",
       "│    │    └─PrenormResidualConnection: 3-13        [1, 512, 64, 64]          2,360,320\n",
       "│    └─VAE_AttentionBlock: 2-6                     [1, 512, 64, 64]          1,024\n",
       "│    │    └─MultiheadAttention: 3-14               [1, 4096, 512]            1,050,624\n",
       "│    └─VAE_Block: 2-7                              [1, 512, 64, 64]          --\n",
       "│    │    └─PrenormResidualConnection: 3-15        [1, 512, 64, 64]          2,360,320\n",
       "│    │    └─PrenormResidualConnection: 3-16        [1, 512, 64, 64]          2,360,320\n",
       "│    └─GroupNorm: 2-8                              [1, 512, 64, 64]          1,024\n",
       "│    └─SiLU: 2-9                                   [1, 512, 64, 64]          --\n",
       "├─Sequential: 1-4                                  [1, 8, 64, 64]            --\n",
       "│    └─Conv2d: 2-10                                [1, 8, 64, 64]            36,872\n",
       "│    └─Conv2d: 2-11                                [1, 8, 64, 64]            72\n",
       "====================================================================================================\n",
       "Total params: 23,237,584\n",
       "Trainable params: 23,237,584\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 285.62\n",
       "====================================================================================================\n",
       "Input size (MB): 3.21\n",
       "Forward/backward pass size (MB): 2584.22\n",
       "Params size (MB): 88.74\n",
       "Estimated Total Size (MB): 2676.17\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(enc, [(1, 3, 512, 512), (1, 4, 64, 64)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SwitchSequential.forward() missing 1 required positional argument: 'time'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m time \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m1\u001b[39m, config\u001b[38;5;241m.\u001b[39munet_time_emb_dim))\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\foret\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\foret\\OneDrive\\Рабочий стол\\Projects\\Stable_diffusion\\src\\model\\unet.py:321\u001b[0m, in \u001b[0;36mUNet.forward\u001b[1;34m(self, x, time)\u001b[0m\n\u001b[0;32m    318\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_embedding(time)\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder:\n\u001b[1;32m--> 321\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\foret\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[1;31mTypeError\u001b[0m: SwitchSequential.forward() missing 1 required positional argument: 'time'"
     ]
    }
   ],
   "source": [
    "time = torch.randn((1, config.unet_time_emb_dim))\n",
    "model(out, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 77])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = CLIPEncoder(config.vocab_size, config.clip_emb_dim, config.clip_seq_len,\n",
    "                   config.clip_attn_num_heads, config.clip_emb_dim_scale_factor, \n",
    "                   config.clip_num_layers, config.clip_dropout).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123060480"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in clip.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNet_AttentionBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_emb = clip(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 77, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 64, 64])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = VAE_Decoder(config.vae_latent_dim, config.vae_features_dims, config.vae_num_groups, config.vae_dropout, config.vae_num_heads, config.img_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32367379\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in dec.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = dec.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 64, 64])\n",
      "torch.Size([1, 512, 64, 64])\n",
      "torch.Size([1, 512, 64, 64])\n",
      "torch.Size([1, 512, 128, 128])\n",
      "torch.Size([1, 256, 256, 256])\n",
      "torch.Size([1, 128, 512, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 512, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec(out).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
